---
title: Papers of CogSci 2025, pt 1
date: 2025-11-17
tags:
  - conferences
  - journal-club
  - cognitive-science
tufte: false
draft: false
---
CogSci---or, rather, the Annual Meeting of [the Cognitive Science Society](https://cognitivesciencesociety.org/)---is probably my favorite academic conference.  It has Goldilocks mixes of size (not too big, not too small) and research breadth (not purely computational, not purely experimental) that makes it very stimulating to attend.  This past year, however, I didn't attend both because San Francisco wasn't an exciting place to travel for me personally and because a lot of our projects didn't fit with the submission deadline.  

The FOMO was still real, however, and so I'm here going to catalogue some papers that seem interesting to me from the proceedings (in no particular order).  Maybe with a brief sentence or two about why.  Note: given how my mind works, what this actually means is that I'm also clearing out tons of tabs from my browser that have been open for months.  Win-win.

- "[Words with more diverse semantic networks are more readily extended to novel meanings](https://escholarship.org/uc/item/2fc6m280)".  Network analysis of word meaning combined with lexical change.
- "[Simulating the Emergence of Differential Case Marking with Communicating Neural-Network Agents](https://escholarship.org/uc/item/5dr7h5tp)": a phenomenon I'm recently interested in investigated using methods I've worked on in the past.  Also saw this one as a talk in Göteborg in late 2024.  And here's [an experimental paper](https://escholarship.org/uc/item/3hc1g645) on differential argument marking in artificial language learning.
- "[Learning Efficient Recursive Numeral Systems via Reinforcement Learning](https://escholarship.org/uc/item/3cc5053z)": it was Emil Carlsson's PhD defense---of which this paper was a chapter---that brought me to Göteborg in the first place.
- "[Soft production preferences emerge from a bottleneck on memory](https://escholarship.org/uc/item/8d87v78d)": explicit modeling of memory bottlenecks during language production yields novel, testable predictions.
- "[Toward a Formal Pragmatics of Explanation](https://escholarship.org/uc/item/0ch6z55z)": saw this one at an event honoring [my PhD advisor](https://staff.fnwi.uva.nl/j.vanbenthem/)'s 75th birthday and enjoyed it, so was happy to see the paper version.
- "[Constituency tests in human adults' language of thought for geometry](https://escholarship.org/uc/item/3716162z)".  I'm a fan of the Language of Thought hypothesis and its resurgence in the past two decades or so.  It's interesting to see _cosntituency tests_ applied to such languages, especially for a domain (geometry) that's not paradigmatically linguistically structured.  Can similar methods be used to identify the primitives in an LoT (one of the main questions in any application)?
- "[Can input statistics over-ride a prior bias in morpheme ordering? A test case with gender and number](https://escholarship.org/uc/item/6n03n959)".  Saldana, Culbertson, and others write an artificial language study on morpheme ordering? I read it.
- "[Efficient compression in locomotion verbs across languages](https://escholarship.org/uc/item/48w0h6jw)": information bottleneck applied to verb meaning, a less "static" domain.  I want to check how exactly they built the meaning space here.
- "[Function shapes form: Compositionality emerges from communicative needs, not environmental structure alone](https://escholarship.org/uc/item/4tw1c3gn)".  Manipulating communicative context has an effect on the emergence of "compositional" languages (i.e. disentangled meanings emerge only when the relevant factors are communicatively useful).
- "[Modelling compounding across languages with analogy and composition](https://escholarship.org/uc/item/7k26z883)": I was an external examiner of Aotao Xu's PhD thesis, which included this paper.  Cool formal modeling of multiple intepretive strategies, applied to novel compounds.